# -*- coding: utf-8 -*-
"""Speech Emotion Recognition

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w-ZRcfg7Y5CWxiOjm-Ug1g9omocMOtmU
"""

from google.colab import files
files.upload()  # This will open a file picker for uploading kaggle.json



from google.colab import files
uploaded = files.upload()  # This will open a file picker for uploading kaggle.json

if 'kaggle.json' in uploaded:
    # Move kaggle.json to the correct location
    import os
    os.rename('kaggle.json', '/root/.kaggle/kaggle.json')

    # Set permissions for the API key
    !chmod 600 /root/.kaggle/kaggle.json
else:
    print("Error: kaggle.json not uploaded. Please upload the file.")

!kaggle datasets download -d ajaykumar254/toronto-emotional-speech-set-tess

!unzip /content/toronto-emotional-speech-set-tess.zip -d /content/tess_dataset/

import os

# List the contents of the dataset folder
dataset_path = '/content/tess_dataset/'
files = os.listdir(dataset_path)
print(files)

# Check if the two directories exist
folder1 = '/content/tess_dataset/tess toronto emotional speech set data'
folder2 = '/content/tess_dataset/TESS Toronto emotional speech set data'

# List contents of both directories
print("Contents of 'tess toronto emotional speech set data':")
print(os.listdir(folder1))

print("\nContents of 'TESS Toronto emotional speech set data':")
print(os.listdir(folder2))

emotion = 'OAF_happy'
emotion_files = os.listdir(os.path.join(folder2, emotion))

# Check the first few files
print(emotion_files[:5])

import os

folder1 = '/content/tess_dataset/tess toronto emotional speech set data'
folder2 = '/content/tess_dataset/TESS Toronto emotional speech set data'

print("Contents of 'tess toronto emotional speech set data':")
print(os.listdir(folder1))

print("\nContents of 'TESS Toronto emotional speech set data':")
print(os.listdir(folder2))

import librosa
import os

emotion = 'OAF_happy'

# List the first 5 audio files in the 'happy' folder
emotion_files = os.listdir(os.path.join(folder2, emotion))
print("First 5 audio files in the 'happy' folder:", emotion_files[:5])

# Load the first audio file
audio_file = emotion_files[0]
audio_path = os.path.join(folder2, emotion, audio_file)

# Load the audio file using librosa
y, sr = librosa.load(audio_path, sr=None)
print(f"Loaded audio: {audio_file}")
print(f"Audio shape: {y.shape}, Sample rate: {sr}")

import librosa
import os


emotion = 'OAF_Sad'
# List the first 5 audio files in the 'happy' folder
emotion_files = os.listdir(os.path.join(folder2, emotion))
print("First 5 audio files in the 'OAF_Sad' folder:", emotion_files[:5])

# Load the first audio file
audio_file = emotion_files[0]
audio_path = os.path.join(folder2, emotion, audio_file)

# Load the audio file using librosa
y, sr = librosa.load(audio_path, sr=None)
print(f"Loaded audio: {audio_file}")
print(f"Audio shape: {y.shape}, Sample rate: {sr}")

import os

# Define the path to the dataset
dataset_path = '/content/tess_dataset/TESS Toronto emotional speech set data'

labels = [folder for folder in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, folder))]

# Print the labels
print("Labels in the dataset:", labels)

import os
import pandas as pd

# Define the path to the dataset
dataset_path = '/content/tess_dataset/TESS Toronto emotional speech set data'

labels = [folder for folder in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, folder))]

# Create an empty list to store the data
data = []

# Loop through each label
for label in labels:
    label_path = os.path.join(dataset_path, label)

    # Loop through each file in the label folder
    for file in os.listdir(label_path):

        file_path = os.path.join(label_path, file)
        if os.path.isfile(file_path):

            data.append({
                'file': file,
                'label': label,
                'file_path': file_path
            })

# Convert the list of data into a DataFrame
df = pd.DataFrame(data)


label_mapping = {
    "YAF_sad": "sad",
    "OAF_Sad": "sad",
    "OAF_Pleasant_surprise": "pleasant_surprise",
    "YAF_pleasant_surprised": "pleasant_surprise",
    "YAF_fear": "fear",
    "OAF_Fear": "fear",
    "YAF_disgust": "disgust",
    "OAF_disgust": "disgust",
    "YAF_neutral": "neutral",
    "OAF_neutral": "neutral",
    "YAF_happy": "happy",
    "OAF_happy": "happy",
    "YAF_angry": "angry",
    "OAF_angry": "angry",
}

# Create a DataFrame for label counts
label_counts = pd.DataFrame([
    {"label": "YAF_sad", "count": 200},
    {"label": "OAF_Pleasant_surprise", "count": 200},
    {"label": "YAF_fear", "count": 200},
    {"label": "YAF_disgust", "count": 200},
    {"label": "YAF_pleasant_surprised", "count": 200},
    {"label": "OAF_angry", "count": 200},
    {"label": "YAF_neutral", "count": 200},
    {"label": "OAF_happy", "count": 200},
    {"label": "OAF_disgust", "count": 200},
    {"label": "OAF_Sad", "count": 200},
    {"label": "OAF_Fear", "count": 200},
    {"label": "YAF_happy", "count": 200},
    {"label": "YAF_angry", "count": 200},
    {"label": "OAF_neutral", "count": 200},
])

# Add normalized labels to the `df`
df['normalized_label'] = df['label'].map(label_mapping)

# Merge the label counts with the main DataFrame
df = df.merge(label_counts, on='label', how='left')

# Print DataFrame
print(df.head())

df.head()

df = df.drop('label', axis=1)

df = df.rename(columns={'normalized_label': 'label'})

df = df.drop('count', axis=1)

df.head()

df.shape

df.tail()

df.label.value_counts()

import seaborn as sns
import matplotlib.pyplot as plt
sns.countplot(df.label)

!pip install librosa soundfile matplotlib
import librosa
import librosa.display
import matplotlib.pyplot as plt
import soundfile as sf
import os
import pandas as pd
import seaborn as sns

def waveform_plot(data, sr, emotion):
    plt.figure(figsize=(10, 4))
    # Use librosa.display.waveshow to display the waveform
    librosa.display.waveshow(data, sr=sr)
    plt.xlabel("Time (s)")
    plt.ylabel("Amplitude")
    plt.title(f"Waveform of {emotion}")
    plt.show()

def spectrogram_plot(data, sr, emotion):
    X = librosa.stft(data)
    Xdb = librosa.amplitude_to_db(abs(X))
    plt.figure(figsize=(10, 4))
    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')
    plt.colorbar()
    plt.title(f"Spectrogram of {emotion}")
    plt.show()

from IPython.display import Audio # Import the Audio object

emotion = 'sad'

path = df.loc[df['label'] == emotion, 'file_path'].iloc[1]

try:
    data, sampling_rate = librosa.load(path, sr=None)
    waveform_plot(data, sampling_rate, emotion)
    spectrogram_plot(data, sampling_rate, emotion)
except FileNotFoundError:
    print(f"Error: File not found at path: {path}")
except sf.LibsndfileError as e:
    print(f"Error loading audio file: {e}")
    print(f"Check if the file is corrupted or in a supported format.")
Audio(path)

"""## Feature Extraction"""

def extract_mfcc(filename):
  y,sr = librosa.load(filename, duration = 3, offset=0.5)
  mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)
  return mfcc

import numpy as np
extract_mfcc(df['file_path'][0])

X_mfcc = df['file_path'].apply(lambda x: extract_mfcc(x))

X_mfcc

X = np.expand_dims(X_mfcc, axis=1)
X.shape

from sklearn.preprocessing import LabelEncoder

# Create a LabelEncoder object
le = LabelEncoder()

# Fit the encoder to labels and transform them
df['label_encoded'] = le.fit_transform(df['label'])

from keras.utils import to_categorical
y = to_categorical(df['label_encoded'])

y

"""# Building the Model"""

# LSTM
from keras.models import Sequential
from keras.layers import Dense, Dropout, LSTM
model = Sequential([
    LSTM(123, return_sequences= False, input_shape=(40,1)),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(7, activation='softmax')
])
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

X = np.stack(X_mfcc.values)

X = X.reshape(X.shape[0], X.shape[1], 1)

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import numpy as np

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
history = model.fit(X, y, validation_split=0.2, epochs=30, batch_size=64, shuffle=True)

# Predict on the test data
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

class_names = df['label'].unique()

print(classification_report(y_true, y_pred_classes, target_names=class_names))

from sklearn.metrics import accuracy_score
# Compute accuracy
manual_accuracy = accuracy_score(y_true, y_pred_classes)
print(f"Model Accuracy: {manual_accuracy * 100:.2f}%")

epochs = range(1, 31)  # Create a range of values from 1 to 30
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
plt.plot(epochs, acc, label='Training Accuracy')
plt.plot(epochs, val_acc, label='Validation Accuracy')
plt.legend()
plt.show()

"""# Save Model"""

import joblib

# Save the model using joblib
joblib.dump(model, 'speech.joblib')
print("Model saved as speech.joblib")

from tensorflow.keras.models import load_model
import joblib


# Save the model to an h5 file
model.save('my_model.h5')
print("Model saved as my_model.h5")


# Load the saved model
loaded_model = load_model('my_model.h5')